{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GroundState Energy from Coulomb Matrices\n",
    "\n",
    "This dataset contains ground state energies of 16,242 molecules calculated by quantum mechanical simulations.\n",
    "\n",
    "The data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the Pubchem Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the Quantum Espresso package.\n",
    "\n",
    "In the csv file, the first column (X1) is the data index.\n",
    "\n",
    "The dataset was used for a [publication using a tree based ML Framework](https://arxiv.org/pdf/1609.07124.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "We create a class that inherits from torch's `Dataset` class to create our own dataset object. It must include the three given methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class GS_from_CM_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_data, transform=None):\n",
    "        \n",
    "        self.path_to_data = path_to_data\n",
    "        if os.path.exists(path_to_data):\n",
    "            self.data = pd.read_csv(path_to_data)\n",
    "        else:\n",
    "            raise FileExistsError('No dataset found')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        X = self.data.drop(columns=['id', 'pubchem_id', 'Eat'])\n",
    "        y = self.data['Eat']\n",
    "        \n",
    "        energy = self.data.iloc[idx, -1]\n",
    "        CMat = self.data.iloc[idx, 1:-2]\n",
    "\n",
    "        # sample = {'CMat': CMat, 'energy': energy}\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     sample = self.transform(sample)\n",
    "            \n",
    "        # return sample\n",
    "        return torch.tensor(CMat).to(torch.float), torch.tensor(energy).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16242\n",
      "0 torch.Size([1275]) tensor(-19.0138)\n",
      "1 torch.Size([1275]) tensor(-10.1610)\n",
      "2 torch.Size([1275]) tensor(-9.3766)\n",
      "3 torch.Size([1275]) tensor(-13.7764)\n",
      "4 torch.Size([1275]) tensor(-8.5371)\n"
     ]
    }
   ],
   "source": [
    "dataset = GS_from_CM_Dataset(path_to_data='data/GS_from_CM/GS_from_CM_data.csv')\n",
    "\n",
    "# Just checking that everything works fine\n",
    "print(len(dataset))\n",
    "for i in range(5):\n",
    "    sample_X, sample_y = dataset[i]\n",
    "    print(i, sample_X.shape, sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the DataLoader function to use the dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(dataset)\n",
    "\n",
    "# input_len = dataset[0]['CMat'].shape[0]\n",
    "input_len = dataset[0][0].shape[0]\n",
    "batch_size = 32\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, (int(N*0.85), N - int(N*0.85)))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start to build our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # The input is a 1275 vector\n",
    "        self.linear_relu_block = nn.Sequential(\n",
    "            nn.Linear(input_len, 16, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_block(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = SimpleNN()\n",
    "model.eval()\n",
    "\n",
    "# Check if it works\n",
    "random_result = model(torch.rand(input_len))\n",
    "print(random_result.shape)\n",
    "# print(model(next(iter(train_dataloader))[0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model. We use the SGD method, since I don't know how the rest work (TODO: Learn the others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 2\n",
    "\n",
    "SGD_opt = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "MSE_fn = nn.MSELoss()\n",
    "\n",
    "def train_epoch(train_data, model, optimizer, loss_fn):\n",
    "    for batch, (X, y) in enumerate(train_data):\n",
    "        # Prediction and loss\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # Calculate gradient and backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f'Current {batch * batch_size:6d} / {N:6d}. Train MSE = {loss:4.4f}', end='\\r')\n",
    "    return loss\n",
    "\n",
    "def test_epoch(test_data, model, loss_fn):\n",
    "    N = len(test_data.dataset)\n",
    "    N_batch = N // len(test_data)\n",
    "    Mse = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(test_data):\n",
    "            y_pred = model(X)\n",
    "            Mse += loss_fn(y_pred, y).item()\n",
    "    print(f'\\nTest MSE {Mse / N_batch:4.4f}')\n",
    "    return Mse / N_batch\n",
    "\n",
    "def train_loop(train_data, test_data, model, optimizer, loss_fn, epochs=1):\n",
    "    train_mse = []\n",
    "    test_mse = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        print('-'*30)\n",
    "        \n",
    "        tr_mse = train_epoch(train_data, model, optimizer, loss_fn)\n",
    "        te_mse = test_epoch(test_data, model, loss_fn)\n",
    "        \n",
    "        train_mse.append(tr_mse)\n",
    "        test_mse.append(te_mse)\n",
    "    return train_mse, test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the model and its training loop. Let's put it to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current  12800 /  16242. Train MSE = 43.09290\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([13, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/eloi/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE 82056.7295\n",
      "Epoch 2/2\n",
      "------------------------------\n",
      "Test MSE 40428.98966242. Train MSE = 11.1886\n"
     ]
    }
   ],
   "source": [
    "train_mse, test_mse = train_loop(train_dataloader, test_dataloader, model, SGD_opt, MSE_fn, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
