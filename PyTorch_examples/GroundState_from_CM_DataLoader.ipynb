{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GroundState Energy from Coulomb Matrices\n",
    "\n",
    "This [dataset](https://www.kaggle.com/datasets/burakhmmtgl/energy-molecule) contains ground state energies of 16,242 molecules calculated by quantum mechanical simulations.\n",
    "\n",
    "The data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the Pubchem Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the Quantum Espresso package.\n",
    "\n",
    "In the csv file, the first column (X1) is the data index.\n",
    "\n",
    "The dataset was used for a [publication using a tree based ML Framework](https://arxiv.org/pdf/1609.07124.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "We create a class that inherits from torch's `Dataset` class to create our own dataset object. It must include the three given methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GS_from_CM_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path_to_data, transform=None):\n",
    "        \n",
    "        self.path_to_data = path_to_data\n",
    "        if os.path.exists(path_to_data):\n",
    "            self.data = pd.read_csv(path_to_data)\n",
    "        else:\n",
    "            raise FileExistsError('No dataset found')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        energy = self.data.iloc[idx, -1]\n",
    "        CMat = self.data.iloc[idx, 1:-2]\n",
    "\n",
    "        return torch.tensor(CMat).to(torch.float), torch.tensor(energy).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dataloader\n",
    "dataset = GS_from_CM_Dataset(path_to_data='data/GS_from_CM/GS_from_CM_data.csv')\n",
    "\n",
    "# Just checking that everything works fine\n",
    "print(len(dataset))\n",
    "for i in range(5):\n",
    "    sample_X, sample_y = dataset[i]\n",
    "    print(i, sample_X.shape, sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the DataLoader function to use the dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_all = len(dataset)\n",
    "\n",
    "# input_len = dataset[0]['CMat'].shape[0]\n",
    "input_len = dataset[0][0].shape[0]\n",
    "batch_size = 32\n",
    "\n",
    "subset = 1\n",
    "\n",
    "used_data, _ = torch.utils.data.random_split(dataset, (int(N_all*subset), N_all - int(N_all*subset)))\n",
    "\n",
    "N = len(used_data)\n",
    "print(f'Using a subset of {N} data out of {N_all}')\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(used_data, (int(N*0.9), N - int(N*0.9)))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start to build our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # The input is a 1275 vector\n",
    "        self.linear_relu_block = nn.Sequential(\n",
    "            nn.Linear(input_len, 16, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_block(x)\n",
    "        return logits.squeeze()\n",
    "    \n",
    "    \n",
    "model = SimpleNN()\n",
    "model.eval()  # Congelas gradients\n",
    "\n",
    "# Check if it works\n",
    "random_result = model(torch.rand(input_len))\n",
    "print(random_result.shape)\n",
    "# print(model(next(iter(train_dataloader))[0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model. We use the SGD method, since I don't know how the rest work (TODO: Learn the others)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "SGD_opt = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "MSE_fn = nn.MSELoss()\n",
    "\n",
    "def train_epoch(train_data, model, optimizer, loss_fn):\n",
    "    for batch, (X, y) in enumerate(train_data):\n",
    "        # print(X.shape)\n",
    "        # print(y.shape)\n",
    "        # Prediction and loss\n",
    "        # start = time.perf_counter()\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y.squeeze())\n",
    "        \n",
    "        # Calculate gradient and modify parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # end = time.perf_counter()\n",
    "        # timer = end-start\n",
    "        # print(timer)\n",
    "        \n",
    "        if (batch+1) % (len(train_data) // 10) == 0:\n",
    "            print(f'Current {batch * batch_size:6d} / {N:6d}. Train MSE = {loss:4.4f}', end='\\r')\n",
    "    return loss.item()\n",
    "\n",
    "def test_epoch(test_data, model, loss_fn):\n",
    "    # N = len(test_data.dataset)\n",
    "    N = len(test_data.dataset)\n",
    "    Mse = 0\n",
    "    for X, y in test_data:\n",
    "    \n",
    "        # with torch.no_grad():\n",
    "        model.eval()\n",
    "        # for X, y in test_data:\n",
    "        y_pred = model(X)\n",
    "        Mse += loss_fn(y_pred, y.squeeze()).item()\n",
    "    print(f'\\nTest MSE {Mse / N:4.4f}')\n",
    "    return Mse / N\n",
    "\n",
    "def train_loop(train_data, test_data, model, optimizer, loss_fn, epochs=1):\n",
    "    train_mse = []\n",
    "    test_mse = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "        print('-'*50)\n",
    "        \n",
    "        tr_mse = train_epoch(train_data, model, optimizer, loss_fn)\n",
    "        te_mse = test_epoch(test_data, model, loss_fn)\n",
    "        \n",
    "        train_mse.append(tr_mse)\n",
    "        test_mse.append(te_mse)\n",
    "    return train_mse, test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the model and its training loop. Let's put it to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "start = perf_counter()\n",
    "train_mse, test_mse = train_loop(train_dataloader, test_dataloader, model, SGD_opt, MSE_fn, epochs=epochs)\n",
    "end = perf_counter()\n",
    "\n",
    "print(f'\\nRun time for {epochs} epochs was {end - start:>8f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is much slower than the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_mse, label='train')\n",
    "plt.plot(test_mse, label='test')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
