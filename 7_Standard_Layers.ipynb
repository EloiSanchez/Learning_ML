{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Layers\n",
    "\n",
    "We will now see some examples of typical layers in DL.\n",
    "\n",
    "Usually, layers have a batch axis, although frameworks and usually math take them implicitly.\n",
    "\n",
    "A [typical neural network](https://dmol.pub/_images/nn.svg) that takes 128x128 images with 3 channels (RGB) and outputs a vector of 128 probabilities that codify the object seen by the NN (cat, vase, crane...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameters\n",
    "\n",
    "We saw from the Full connected (FC)/Dense layer that we have to choose if we use bias, the activation, and the output shape. As we learn about more complex layers, there will be more choices. These choices begin to accumulate and in a neural network you may have billions of possible combinations of them. These choices about shape, activation, initialization, and other layer arguments are called hyperparameters. They are parameters in the sense that they can be tuned, but they are not trained on our data so we call them hyperparameters to distinguish them from the “regular” parameters like value of weights and biases in the layers. The name is inherited from Bayesian statistics.\n",
    "\n",
    "### 1.1. Validation\n",
    "\n",
    "The number of hyperparameters is high enough that overfitting can actually occur by choosing hyperparameters that minimize error on the test set. This is surprising because we don’t explicitly train hyperparameters. Nevertheless, you will find in your own work that if you use the test data extensively in hyperparameter tuning and for assessing overfitting of the regular training parameters, your performance will be overfit to the testing data. To combat this, we split our data three ways in deep learning:\n",
    "\n",
    "1. Training data: used for trainable parameters.\n",
    "2. Validation data: used to choose hyperparameters or measure overfitting of training data\n",
    "3. Test data: data not used for anything except final reported error\n",
    "\n",
    "To clean-up our nomenclature here, we use the word generalization error to refer to performance on a hypothetical infinite stream of unseen data. So regardless of if you split three-ways or use other approaches, generalization error means error on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Common Layers\n",
    "\n",
    "### 2.1. Convolutions\n",
    "\n",
    "Convolutions are a layer typically used in image processing. Each convolutin layer has a grid $(H,W)$ that takes $H\\times W$ pixels from the image and a set of filters $F$ that are trained to produce an output. Adding as well the channels we see that the layer has shape $(C, H, W, F)$.\n",
    "\n",
    "Convolution Layers are **equivariant**, meaning that if the input (cat) is displaced in the image, the output is displaced as well. Another type of property is **invariance**, where the position of the input is irrelevant to the output.\n",
    "\n",
    "Another important term is **padding**. If you want a grid of, say (32,32), but your input is (30,30), you can add 2 extra pixels to the sides and top and bottom parts, fill them with 0s, and obtain an image of (32,32).\n",
    "\n",
    "### 2.2. Pooling\n",
    "\n",
    "Convolutions are commonly paired with pooling layers because pooling also is translationally equivariant. If your goal is to produce a single number (regression) or class (classification) from an input image or sequence, you need to reduce the rank to 0, a scalar. After a convolution, you could use a reduction like average or maximum. It has been shown empirically that reducing the number of elements of your features more gradually is better. One way is through pooling. Pooling is similar to convolutions, in that you define a kernel shape (called window shape), but pooling has no trainable parameters. Instead, you run a window across your input grid and compute a reduction. Commonly an average or maximum is computed. For example, you might use three rounds of convolutions and pooling to take an image from $32\\times 32$ down to a $4\\times 4$. Read more about [pooling here](https://d2l.ai/chapter_convolutional-neural-networks/pooling.html).\n",
    "\n",
    "### 2.2. Embedding\n",
    "\n",
    "Another important type of input layers are embeddings. Embeddings convert integers into vectors. They are typically used to convert characters or words into numerical vectors. The characters or words are first converted into tokens separately as a pre-processing step and then the input to the embedding layer is the indices of the token. The indices are integer values that index into a dictionary of all possible tokens. It sounds more complex than it is. For example, we might tokenize characters in the alphabet. There are 26 tokens (letters) in the alphabet (dictionary of tokens) and we could convert the word “hello” into the indices [7,4,11,11,14], where 7 means the 7th letter of the alphabet.\n",
    "\n",
    "After converting into indices, an embedding layer converts these indices into dense vectors of a chosen dimension. The rationale behind embeddings is to go from a large discrete space (e.g., all words in the English language) into a much smaller space of real numbers (e.g., vectors of size 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example\n",
    "\n",
    "At this point, we have enough common layers to try to build a neural network. We will combine these three layers to predict if a protein is soluble. Our [dataset](https://pubmed.ncbi.nlm.nih.gov/23926206/) consists of proteins known to be soluble or insoluble. As usual, the code below sets-up our imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 12:42:34.143824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:42:34.143841: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "# import dmol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is binary classification. The data is split into two: positive and negative examples. We’ll need to rearrange a little into a normal dataset with labels and training/testing split. We also really really need to shuffle our data, so it doesn’t see all positives and then all negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18453 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 12:49:17.554485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 12:49:17.554895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.554938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.554976: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.555014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.555055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.555092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.555130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.555167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-06 12:49:17.555173: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-06 12:49:17.555430: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-06 12:49:17.556706: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29524800 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/whitead/dmol-book/raw/master/data/solubility.npz\",\n",
    "    \"solubility.npz\",\n",
    ")\n",
    "with np.load(\"solubility.npz\") as r:\n",
    "    pos_data, neg_data = r[\"positives\"], r[\"negatives\"]\n",
    "\n",
    "\n",
    "# create labels and stich it all into one\n",
    "# tensor\n",
    "labels = np.concatenate(\n",
    "    (\n",
    "        np.ones((pos_data.shape[0], 1), dtype=pos_data.dtype),\n",
    "        np.zeros((neg_data.shape[0], 1), dtype=pos_data.dtype),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "features = np.concatenate((pos_data, neg_data), axis=0)\n",
    "# we now need to shuffle before creating TF dataset\n",
    "# so that our train/test/val splits are random\n",
    "i = np.arange(len(labels))\n",
    "np.random.shuffle(i)\n",
    "labels = labels[i]\n",
    "features = features[i]\n",
    "full_data = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "# now split into val, test, train\n",
    "N = pos_data.shape[0] + neg_data.shape[0]\n",
    "print(N, \"examples\")\n",
    "split = int(0.1 * N)\n",
    "test_data = full_data.take(split).batch(16)\n",
    "nontest = full_data.skip(split)\n",
    "val_data, train_data = nontest.take(split).batch(16), nontest.skip(split).shuffle(\n",
    "    1000\n",
    ").batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to modeling, let’s examine our data. The protein sequences have already been tokenized. There are 20 possible values at each position because there are 20 amino acids possible in proteins. Let’s see a soluble protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8785, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that integers/indices are used because our data is tokenized already. To make our data all be the same input shape, a special token (0) is inserted at the end indicating no amino acid is present. This needs to be treated carefully, because it should be zeroed throughout the network. Luckily this is built into Keras, so we do not need to worry about it.\n",
    "\n",
    "This data is perfect for an embedding because we need to convert token indices to real vectors. Then we will use 1D convolutions to look for sequence patterns with pooling. We need to then make sure our final layer is a sigmoid, just like in Classification.\n",
    "\n",
    "We begin with an embedding. We’ll use a 2-dimensional embedding, which gives us two channels for our sequence. We’ll just choose our kernel filter size for the 1D convolution to be 5 and we’ll use 16 filters. Beyond that, the rest of the network is about distilling gradually into a final class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 16)           336       \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 196, 16)           1296      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 49, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 47, 16)            784       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 23, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 21, 16)            784       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 10, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               41216     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,929\n",
      "Trainable params: 60,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# make embedding and indicate that 0 should be treated specially\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=21, output_dim=16, mask_zero=True, input_length=pos_data.shape[-1]\n",
    "    )\n",
    ")\n",
    "\n",
    "# INFO FOR EMBEDDING\n",
    "\n",
    "# input_dim: The size of the tokens on the input + 1. Since aminoacids\n",
    "# are encoded from 1 to 20 we use input_dim = 21\n",
    "\n",
    "# output_dim: The dimension that outputs of this layer.\n",
    "\n",
    "# mask_zero: Indicates that 0 should be ignored because it has no meaning.\n",
    "\n",
    "# input_length: The size of the vectors (tensors) that we are inputting to the layer\n",
    "\n",
    "\n",
    "# now we move to convolutions and pooling\n",
    "model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=5, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=4))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=3, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=3, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# now we flatten to move to hidden dense layers.\n",
    "# Flattening just removes all axes except 1 (and implicit batch is still in there as always!)\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "922/923 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5296 - binary_accuracy: 0.5296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 13:27:52.333302: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29524800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923/923 [==============================] - 5s 4ms/step - loss: 0.6910 - accuracy: 0.5294 - binary_accuracy: 0.5294 - val_loss: 0.6901 - val_accuracy: 0.5393 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6772 - accuracy: 0.5675 - binary_accuracy: 0.5675 - val_loss: 0.6690 - val_accuracy: 0.5778 - val_binary_accuracy: 0.5778\n",
      "Epoch 3/10\n",
      "923/923 [==============================] - 4s 5ms/step - loss: 0.6641 - accuracy: 0.5894 - binary_accuracy: 0.5894 - val_loss: 0.6706 - val_accuracy: 0.5664 - val_binary_accuracy: 0.5664\n",
      "Epoch 4/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6538 - accuracy: 0.6027 - binary_accuracy: 0.6027 - val_loss: 0.6621 - val_accuracy: 0.5919 - val_binary_accuracy: 0.5919\n",
      "Epoch 5/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6454 - accuracy: 0.6169 - binary_accuracy: 0.6169 - val_loss: 0.6602 - val_accuracy: 0.6011 - val_binary_accuracy: 0.6011\n",
      "Epoch 6/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6351 - accuracy: 0.6324 - binary_accuracy: 0.6324 - val_loss: 0.6683 - val_accuracy: 0.5827 - val_binary_accuracy: 0.5827\n",
      "Epoch 7/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6262 - accuracy: 0.6388 - binary_accuracy: 0.6388 - val_loss: 0.6628 - val_accuracy: 0.6081 - val_binary_accuracy: 0.6081\n",
      "Epoch 8/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6164 - accuracy: 0.6491 - binary_accuracy: 0.6491 - val_loss: 0.6734 - val_accuracy: 0.6033 - val_binary_accuracy: 0.6033\n",
      "Epoch 9/10\n",
      "923/923 [==============================] - 4s 4ms/step - loss: 0.6045 - accuracy: 0.6602 - binary_accuracy: 0.6602 - val_loss: 0.6796 - val_accuracy: 0.5881 - val_binary_accuracy: 0.5881\n",
      "Epoch 10/10\n",
      "923/923 [==============================] - 4s 5ms/step - loss: 0.5930 - accuracy: 0.6724 - binary_accuracy: 0.6724 - val_loss: 0.6850 - val_accuracy: 0.5870 - val_binary_accuracy: 0.5870\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", \"binary_accuracy\"])\n",
    "# Adam is an optimizer, alternative to SGD\n",
    "\n",
    "result = model.fit(train_data, validation_data=val_data, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result.history[\"loss\"], label=\"training\")\n",
    "plt.plot(result.history[\"val_loss\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see this is a classic case of overfitting, with the validation data rising quickly as we improve our loss on the training data. Indeed, our model is quite expressive in its capability to fit the training data but it is incidentally fititng the noise. We have 61,000 trainable parameters and about 15,000 training examples, so this is not a surprise. However, we still able to learn a little bit – our accuracy is above 50%. This is actually a challenging dataset and the state-of-the art result is [77% accuracy](https://academic.oup.com/bioinformatics/article/34/15/2605/4938490?login=false). We need to expand our tools to include layers that can address overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Back propagation\n",
    "\n",
    "At this stage, we should probably talk about back propagation and its connection to automatic gradient computation (autograds). This is how training “just works” when we take a gradient. This is actually a bit of a complicated topic, but it also nearly invisible to users of modern deep learning packages. Thus, I have chosen to not cover it in this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regularization\n",
    "\n",
    "As we saw in the ML chapters, regularization is a strategy that changes your training procedure (often by adding loss terms) to prevent overfitting. There is a nice argument for it in the bias-variance trade-off regarding model complexity, however this doesn’t seem to hold in practice. It is an empirical process that depends on many variables. Adding regularization if your model is underfit will usually reduce performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Early Stopping\n",
    "\n",
    "The most commonly used and simplest form of regularization is early stopping. Early stopping means monitoring the loss on your validation data and stopping training once it begins to rise. Normally, training is done until converged – meaning the loss stops decreasing. Early stopping tries to prevent overfitting by looking at the loss on unseen data (validation data) and stopping once that begins to rise. This is an example of regularization because the weights are limited to move a fixed distance from their initial value. Just like in L2 regularization, we’re squeezing our trainable weights. Early stopping can be a bit more complicated to implement in practice than it sounds, so check out how frameworks do it before trying to implement yourself (e.g., [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Weight\n",
    "\n",
    "Weight regularization is the addition of terms to the loss that depend on the trainable weights in the solubility model example. These can be L2 or L1. You must choose the strength, which is expressed as a parameter (often denoted $\\lambda$) that should be much less than 1. Typically values of 0.1 to 0.0001 are chosen. This may be broken into **kernel regularization**, which affects the multiplicative weights in a dense or convolution neural network, and **bias regularization**. Bias regularization is rarely seen in practice."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
