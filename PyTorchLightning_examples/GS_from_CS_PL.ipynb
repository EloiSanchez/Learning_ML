{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GroundState Energy from Coulomb Matrices\n",
    "\n",
    "This [dataset](https://www.kaggle.com/datasets/burakhmmtgl/energy-molecule) contains ground state energies of 16,242 molecules calculated by quantum mechanical simulations.\n",
    "\n",
    "The data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the Pubchem Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the Quantum Espresso package.\n",
    "\n",
    "In the csv file, the first column (X1) is the data index.\n",
    "\n",
    "The dataset was used for a [publication using a tree based ML Framework](https://arxiv.org/pdf/1609.07124.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "In this test we do NOT use PyTorch DataLoaders. Instead, we fabricate the batched tensors by hand and ensure that the data is accessed correctly by the training loop.\n",
    "\n",
    "We create a class that inherits from torch's `Dataset` class to create our own dataset object. It must include the three given methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_from_CM_Dataset(path_to_data, transform=None):\n",
    "    if os.path.exists(path_to_data):\n",
    "        data = pd.read_csv(path_to_data)\n",
    "    else:\n",
    "        raise FileExistsError('No dataset found')\n",
    "    data = data.sample(frac=1)\n",
    "    X = data.drop(columns=['id', 'pubchem_id', 'Eat'])\n",
    "    y = data['Eat']\n",
    "    \n",
    "    return torch.tensor(X.to_numpy()).to(torch.float), torch.tensor(y.to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losing 127 datapoints due to batching.\n",
      "Losing 127 datapoints due to batching.\n"
     ]
    }
   ],
   "source": [
    "dataset = GS_from_CM_Dataset(path_to_data='../PyTorch_examples/data/GS_from_CM/GS_from_CM_data.csv')\n",
    "N_all = len(dataset[0])\n",
    "subset = 0.9\n",
    "\n",
    "X_train, y_train, X_test, y_test = \\\n",
    "    dataset[0][:int(N_all*subset)], dataset[1][:int(N_all*subset)], dataset[0][int(N_all*subset):], dataset[1][int(N_all*subset):]\n",
    "N_train = X_train[0].shape[0]\n",
    "# print(datatrain[0].shape[0] + datatest[1].shape[0], dataset[0].shape[0])\n",
    "# print(datatrain[0].shape, datatrain[1].shape, datatest[0].shape, datatest[1].shape)\n",
    "N_val = int(N_train * 0.8)\n",
    "\n",
    "X_train, y_train, X_val, y_val = \\\n",
    "    X_train[:(N_train-N_val)], y_train[:(N_train-N_val)], X_train[(N_train-N_val):], X_train[(N_train-N_val):],\n",
    "\n",
    "\n",
    "def tensorBatch(tensor, batch_size):\n",
    "    \"\"\"I think this only works for one and two dimensional tensors\n",
    "    Returns the batched tensor\n",
    "    \"\"\"\n",
    "    N_batch = tensor.shape[0] // batch_size\n",
    "    N_elems = N_batch * batch_size\n",
    "    \n",
    "    print(f'Losing {tensor.shape[0] - N_elems} datapoints due to batching.')\n",
    "    \n",
    "    return tensor[:N_elems].reshape(N_batch, batch_size, -1).squeeze(), N_batch\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Check that it works. I think it does.\n",
    "# print(X_train.shape, tensorBatch(X_train, batch_size)[0].shape)\n",
    "# print(y_train.shape, tensorBatch(y_train, batch_size)[0].shape)\n",
    "# print(X_test.shape, tensorBatch(X_test, batch_size)[0].shape)\n",
    "# print(y_test.shape, tensorBatch(y_test, batch_size)[0].shape)\n",
    "\n",
    "X_train, N_batch = tensorBatch(X_train, batch_size)\n",
    "y_train, _ = tensorBatch(y_train, batch_size)\n",
    "N_train = N_batch * batch_size\n",
    "# X_test, y_test = [tensorBatch(tens, batch_size) for tens in test_data]\n",
    "\n",
    "def getDataLoader(X, y):\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise IndexError(f'Number of batches is different for the inputs',\n",
    "                         f'First argument -> {X.shape[0]} != {y.shape[0]} <- Second argument')\n",
    "    batched = []\n",
    "    for i in range(X.shape[0]):\n",
    "        batched.append((X[i], y[i]))\n",
    "    return batched\n",
    "\n",
    "train_dataload = getDataLoader(X_train, y_train)\n",
    "test_dataload = (X_test, y_test)\n",
    "val_dataload = (X_val, y_val)\n",
    "\n",
    "input_len = X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of vanilla PyTorch, we will create the model using Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GS_from_CM_model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(input_len, 16, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.energy(X)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        if batch_idx == 0:\n",
    "            print('train', X.shape, y.shape)\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        if batch_idx == 0:\n",
    "            print('test', X.shape, y.shape)\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log('test_loss', loss)\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        if batch_idx == 0:\n",
    "            print('validation', X.shape, y.shape)\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log('val_log', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now directly train the model automatically, performing all test and validation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | energy | Sequential | 20.5 K\n",
      "--------------------------------------\n",
      "20.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.5 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GS_from_CM_model.validation_step() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/eloisanchez/Documents/Learning_ML/PyTorchLightning_examples/GS_from_CS_PL.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eloisanchez/Documents/Learning_ML/PyTorchLightning_examples/GS_from_CS_PL.ipynb#ch0000008?line=3'>4</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/eloisanchez/Documents/Learning_ML/PyTorchLightning_examples/GS_from_CS_PL.ipynb#ch0000008?line=5'>6</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/eloisanchez/Documents/Learning_ML/PyTorchLightning_examples/GS_from_CS_PL.ipynb#ch0000008?line=6'>7</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel, train_dataloaders\u001b[39m=\u001b[39;49m\u001b[39miter\u001b[39;49m(train_dataload), val_dataloaders\u001b[39m=\u001b[39;49mval_dataload)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=750'>751</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=751'>752</a>\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=752'>753</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=766'>767</a>\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=767'>768</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=768'>769</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=769'>770</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=770'>771</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=771'>772</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=720'>721</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=721'>722</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=722'>723</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=723'>724</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=724'>725</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=806'>807</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=807'>808</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=808'>809</a>\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=809'>810</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=810'>811</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=812'>813</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=813'>814</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1231'>1232</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1233'>1234</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1235'>1236</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1237'>1238</a>\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1238'>1239</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1320'>1321</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1321'>1322</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1322'>1323</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1345\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1341'>1342</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1343'>1344</a>\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1344'>1345</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1346'>1347</a>\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1347'>1348</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1413\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1410'>1411</a>\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1411'>1412</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1412'>1413</a>\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1414'>1415</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1416'>1417</a>\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=152'>153</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=153'>154</a>\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=154'>155</a>\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=156'>157</a>\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=157'>158</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=201'>202</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/base.py?line=205'>206</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:128\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=124'>125</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=126'>127</a>\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=127'>128</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=128'>129</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=130'>131</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:226\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=223'>224</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_strategy_hook(\u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mkwargs\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=224'>225</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=225'>226</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mvalidation_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=227'>228</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1761'>1762</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1763'>1764</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1764'>1765</a>\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1766'>1767</a>\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py?line=1767'>1768</a>\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py?line=338'>339</a>\u001b[0m \u001b[39m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py?line=339'>340</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py?line=340'>341</a>\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py?line=341'>342</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py?line=342'>343</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m--> <a href='file:///home/eloisanchez/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py?line=343'>344</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: GS_from_CM_model.validation_step() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "model = GS_from_CM_model()  # Instantiate the model\n",
    "\n",
    "# Get the trainer\n",
    "trainer = pl.Trainer(max_epochs=20)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model=model, train_dataloaders=iter(train_dataload), val_dataloaders=iter(val_dataload))  # WHY PASSED AS ITER WORKS¿?¿?!!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
