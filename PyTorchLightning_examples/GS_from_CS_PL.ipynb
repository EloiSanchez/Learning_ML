{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GroundState Energy from Coulomb Matrices\n",
    "\n",
    "This [dataset](https://www.kaggle.com/datasets/burakhmmtgl/energy-molecule) contains ground state energies of 16,242 molecules calculated by quantum mechanical simulations.\n",
    "\n",
    "The data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the Pubchem Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the Quantum Espresso package.\n",
    "\n",
    "In the csv file, the first column (X1) is the data index.\n",
    "\n",
    "The dataset was used for a [publication using a tree based ML Framework](https://arxiv.org/pdf/1609.07124.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "In this test we do NOT use PyTorch DataLoaders. Instead, we fabricate the batched tensors by hand and ensure that the data is accessed correctly by the training loop.\n",
    "\n",
    "We create a class that inherits from torch's `Dataset` class to create our own dataset object. It must include the three given methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_from_CM_Dataset(path_to_data, transform=None):\n",
    "    if os.path.exists(path_to_data):\n",
    "        data = pd.read_csv(path_to_data)\n",
    "    else:\n",
    "        raise FileExistsError('No dataset found')\n",
    "    data = data.sample(frac=1)\n",
    "    X = data.drop(columns=['id', 'pubchem_id', 'Eat'])\n",
    "    y = data['Eat']\n",
    "    \n",
    "    return torch.tensor(X.to_numpy()).to(torch.float), torch.tensor(y.to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losing 25 datapoints due to batching.\n",
      "Losing 25 datapoints due to batching.\n"
     ]
    }
   ],
   "source": [
    "dataset = GS_from_CM_Dataset(path_to_data='../PyTorch_examples/data/GS_from_CM/GS_from_CM_data.csv')\n",
    "N_all = len(dataset[0])\n",
    "subset = 0.9\n",
    "\n",
    "X_train, y_train, X_test, y_test = \\\n",
    "    dataset[0][:int(N_all*subset)], dataset[1][:int(N_all*subset)], dataset[0][int(N_all*subset):], dataset[1][int(N_all*subset):]\n",
    "N_train = X_train[0].shape[0]\n",
    "# print(datatrain[0].shape[0] + datatest[1].shape[0], dataset[0].shape[0])\n",
    "# print(datatrain[0].shape, datatrain[1].shape, datatest[0].shape, datatest[1].shape)\n",
    "\n",
    "\n",
    "def tensorBatch(tensor, batch_size):\n",
    "    \"\"\"I think this only works for one and two dimensional tensors\n",
    "    Returns the batched tensor\n",
    "    \"\"\"\n",
    "    N_batch = tensor.shape[0] // batch_size\n",
    "    N_elems = N_batch * batch_size\n",
    "    \n",
    "    print(f'Losing {tensor.shape[0] - N_elems} datapoints due to batching.')\n",
    "    \n",
    "    return tensor[:N_elems].reshape(N_batch, batch_size, -1).squeeze(), N_batch\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Check that it works. I think it does.\n",
    "# print(X_train.shape, tensorBatch(X_train, batch_size)[0].shape)\n",
    "# print(y_train.shape, tensorBatch(y_train, batch_size)[0].shape)\n",
    "# print(X_test.shape, tensorBatch(X_test, batch_size)[0].shape)\n",
    "# print(y_test.shape, tensorBatch(y_test, batch_size)[0].shape)\n",
    "\n",
    "X_train, N_batch = tensorBatch(X_train, batch_size)\n",
    "y_train, _ = tensorBatch(y_train, batch_size)\n",
    "# X_test, y_test = [tensorBatch(tens, batch_size) for tens in test_data]\n",
    "\n",
    "def getDataLoader(X, y):\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise IndexError(f'Number of batches is different for the inputs',\n",
    "                         f'First argument -> {X.shape[0]} != {y.shape[0]} <- Second argument')\n",
    "    batched = []\n",
    "    for i in range(X.shape[0]):\n",
    "        batched.append((X[i], y[i]))\n",
    "    return batched\n",
    "\n",
    "train_dataload = getDataLoader(X_train, y_train)\n",
    "test_dataload = (X_test, y_test)\n",
    "\n",
    "input_len = X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of vanilla PyTorch, we will create the model using Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GS_from_CM_model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('I am here')\n",
    "        super().__init__()\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(input_len, 16, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.energy(X)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here\n"
     ]
    }
   ],
   "source": [
    "model = GS_from_CM_model()  # Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | energy | Sequential | 20.5 K\n",
      "--------------------------------------\n",
      "20.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.5 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 19it [00:00, 162.02it/s, loss=117, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21509/2924522710.py:26: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: : 0it [00:00, ?it/s, loss=99.8, v_num=1]      \n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=iter(train_dataload))  # WHY PASSED AS ITER WORKSÂ¿?Â¿?!!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
