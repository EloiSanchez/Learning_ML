{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting GroundState Energy from Coulomb Matrices\n",
    "\n",
    "This [dataset](https://www.kaggle.com/datasets/burakhmmtgl/energy-molecule) contains ground state energies of 16,242 molecules calculated by quantum mechanical simulations.\n",
    "\n",
    "The data contains 1277 columns. The first 1275 columns are entries in the Coulomb matrix that act as molecular features. The 1276th column is the Pubchem Id where the molecular structures are obtained. The 1277th column is the atomization energy calculated by simulations using the Quantum Espresso package.\n",
    "\n",
    "In the csv file, the first column (X1) is the data index.\n",
    "\n",
    "The dataset was used for a [publication using a tree based ML Framework](https://arxiv.org/pdf/1609.07124.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "In this test we do NOT use PyTorch DataLoaders. Instead, we fabricate the batched tensors by hand and ensure that the data is accessed correctly by the training loop.\n",
    "\n",
    "We create a class that inherits from torch's `Dataset` class to create our own dataset object. It must include the three given methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset and dataloaders for pytorch lightining. Note that the data reading is performed at the `__init__` and the `__getindex__` simply access it. This is done on purpose so that everytime the data is accessed it does not have to read/load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GS_from_CM_Dataset(Dataset):\n",
    "    def __init__(self, path_to_data):\n",
    "        if os.path.exists(path_to_data):\n",
    "            self.data = pd.read_csv(path_to_data)\n",
    "        else:\n",
    "            raise FileExistsError('No dataset found')\n",
    "        self.data = self.data.sample(frac=1)\n",
    "        self.X = torch.tensor(self.data.drop(columns=['id', 'pubchem_id', 'Eat']).to_numpy()).to(torch.float)\n",
    "        self.y = torch.tensor(self.data['Eat'].to_numpy()).to(torch.float)\n",
    "        self.length = self.y.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data      -> 10394\n",
      "Validation data -> 3249\n",
      "Test data       -> 2599\n",
      "Total data      -> 16242 = 10394 + 3249 + 2599\n"
     ]
    }
   ],
   "source": [
    "data = GS_from_CM_Dataset(path_to_data='../PyTorch_examples/data/GS_from_CM/GS_from_CM_data.csv')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "data_train, data_test = torch.utils.data.random_split(data, (int(len(data)*0.8), len(data)-int(len(data)*0.8)))\n",
    "data_train, data_val = torch.utils.data.random_split(data_train, (int(len(data_train)*0.8), len(data_train)-int(len(data_train)*0.8)))\n",
    "\n",
    "print(f'Train data      -> {len(data_train)}')\n",
    "print(f'Validation data -> {len(data_test)}')\n",
    "print(f'Test data       -> {len(data_val)}')\n",
    "print(f'Total data      -> {len(data)} = {len(data_train)} + {len(data_test)} + {len(data_val)}')\n",
    "\n",
    "train_loader, test_loader, val_loader = [DataLoader(s, batch_size, shuffle=True, num_workers=4) for s in (data_train, data_test, data_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "\n",
    "Now, instead of vanilla PyTorch, we will create the model using Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GS_from_CM_model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, input_len):\n",
    "        super().__init__()\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(input_len, 16, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.energy(X)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred.squeeze(), y.squeeze())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred.squeeze(), y.squeeze())\n",
    "        self.log('test_loss', loss)\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        pred = self.energy(X)\n",
    "        loss = F.mse_loss(pred.squeeze(), y.squeeze())\n",
    "        self.log('val_log', loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model\n",
    "\n",
    "We can now directly train the model automatically, performing all test and validation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | energy | Sequential | 20.5 K\n",
      "--------------------------------------\n",
      "20.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.5 K    Total params\n",
      "0.082     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:495: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 103/103 [00:02<00:00, 45.27it/s, loss=13.8, v_num=14]\n"
     ]
    }
   ],
   "source": [
    "model = GS_from_CM_model(input_len=data_train[0][0].shape[-1])  # Instantiate the model\n",
    "\n",
    "# Get the trainer\n",
    "trainer = pl.Trainer(max_epochs=20)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)  # WHY PASSED AS ITER WORKS¿?¿?!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eloi/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:495: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 26/26 [00:00<00:00, 93.34it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            13.09735107421875\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 13.09735107421875}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the results we can use `tensorboard --logdir=PyTorchLightning_examples/lightning_logs/` in the terminal"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
